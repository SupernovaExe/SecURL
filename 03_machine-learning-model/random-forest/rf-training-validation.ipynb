{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest Classifier\n",
    "\n",
    "By Steven Sison on December 16, 2023"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Description\n",
    "\n",
    "This document will be used for the preliminary training and evaluation of the random forest classifier. The document includes the necessary processes taken to train the model with the default hyperparameters. This also evaluates the performance of the classifier in terms of accuracy, precision, recall, F1-score, training time, and detection time. Furthermore, this document will only use lexical features and will observe the effect of increasing the number of features used in the model. As this is only for preliminary work, no optimizations, except a simple train-test validation, will be carried out."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preliminaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd                     # For data transformation\n",
    "import numpy as numpy                   # For scientific calculations\n",
    "import seaborn as sns                   # For data visualizations\n",
    "import matplotlib.pyplot as plt         # For plotting\n",
    "import plotly.graph_objects as go       # For plotting\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, cross_val_predict\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score, classification_report\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score, ConfusionMatrixDisplay\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "import time\n",
    "from datetime import datetime\n",
    "import joblib\n",
    "\n",
    "dataset = pd.read_csv(\"final_unbalanced_withLexical.csv\")      # Loading the dataset\n",
    "x_train, x_test, y_train, y_test = train_test_split(dataset.drop(columns=['url_type']), dataset['url_type'], test_size = 0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training and Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Base Model using All Lexical Features Generated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('classifier', RandomForestClassifier())\n",
    "])\n",
    "\n",
    "pipeline.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = pipeline.predict(x_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_test, y_pred, labels=pipeline.classes_)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix = cm, display_labels = pipeline.classes_)\n",
    "disp.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating the Effect of Balanced and Unbalanced Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['url_type'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upsampling\n",
    "\n",
    "from sklearn.utils import resample\n",
    "\n",
    "dataset_benign = dataset[(dataset['url_type'] == 0)]\n",
    "dataset_defacement = dataset[(dataset['url_type'] == 1)]\n",
    "dataset_phishing = dataset[(dataset['url_type'] == 2)]\n",
    "dataset_malware = dataset[(dataset['url_type'] == 3)]\n",
    "\n",
    "dataset_benign_upsampled = resample(dataset_benign,\n",
    "                                        replace=True,\n",
    "                                        n_samples = dataset_benign.shape[0],\n",
    "                                        random_state = 15)\n",
    "\n",
    "dataset_defacement_upsampled = resample(dataset_defacement,\n",
    "                                        replace=True,\n",
    "                                        n_samples = dataset_benign.shape[0],\n",
    "                                        random_state = 15)\n",
    "\n",
    "dataset_phishing_upsampled = resample(dataset_phishing,\n",
    "                                        replace=True,\n",
    "                                        n_samples = dataset_benign.shape[0],\n",
    "                                        random_state = 15)\n",
    "\n",
    "dataset_malware_upsampled = resample(dataset_malware,\n",
    "                                        replace=True,\n",
    "                                        n_samples = dataset_benign.shape[0],\n",
    "                                        random_state = 15)\n",
    "\n",
    "\n",
    "dataset_upsampled = pd.concat([dataset_benign_upsampled, dataset_defacement_upsampled, dataset_malware_upsampled, dataset_phishing_upsampled])\n",
    "\n",
    "# dataset_upsampled.info(0)\n",
    "dataset_upsampled['url_type'].value_counts()\n",
    "\n",
    "x_up_train, x_up_test, y_up_train, y_up_test = train_test_split(dataset_upsampled.drop(columns=['url_type']), dataset_upsampled['url_type'], test_size = 0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pipeline_up = Pipeline([\n",
    "    ('classifier', RandomForestClassifier())\n",
    "])\n",
    "\n",
    "pipeline_up.fit(x_up_train, y_up_train)\n",
    "y_up_pred = pipeline_up.predict(x_up_test)\n",
    "print(classification_report(y_up_test, y_up_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_up = confusion_matrix(y_up_test, y_up_pred, labels=pipeline_up.classes_)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix = cm_up, display_labels = pipeline_up.classes_)\n",
    "disp.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating the Effect of Adding more Lexical Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "\n",
    "for i in range(3):\n",
    "    pipeline = Pipeline([('classifier', RandomForestClassifier())])\n",
    "\n",
    "    temp_url_features = x_up_train.iloc[:, 0:(25*(i+1))]\n",
    "    \n",
    "    pipeline.fit(temp_url_features, y_up_train)\n",
    "    \n",
    "    filename =  'rf_lexical_{}.sav'.format((25*(i+1)))\n",
    "    joblib.dump(pipeline, filename)\n",
    "\n",
    "    url_type_predict = pipeline.predict(x_up_test.iloc[:, 0:(25*(i+1))])\n",
    "\n",
    "    accuracy = accuracy_score(y_up_test, url_type_predict)\n",
    "    recall = recall_score(y_up_test, url_type_predict, average = 'weighted')\n",
    "    precision = precision_score(y_up_test, url_type_predict, average = 'weighted', zero_division=1)\n",
    "    f1 = f1_score(y_up_test, url_type_predict, average = 'weighted')\n",
    "    results.append(((4*(i+1)), accuracy, recall, precision, f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame(results, columns=['Number of Features', 'Accuracy', 'Recall', 'Precision', 'F1-Score'])\n",
    "results = results.sort_values(by='Number of Features', ascending=True)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observations:\n",
    "- Increasing the number of features improves all the class weighted metrics of the model at the cost of a higher training time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Optimizations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With Cross Validation (No Hyperparameter Tuning and Using Upsampled Dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import mean\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "from sklearn.model_selection import KFold\n",
    "from matplotlib import pyplot\n",
    "\n",
    "def evaluating_model(cv):\n",
    "\n",
    "    X, y = dataset_upsampled.drop(columns=['url_type']), dataset_upsampled['url_type']\n",
    "\n",
    "    model = RandomForestClassifier()\n",
    "    scores = cross_val_score(model, X,y, scoring = \"accuracy\", cv = cv, n_jobs=1)\n",
    "\n",
    "    return mean(scores), scores.min(), scores.max()\n",
    "\n",
    "# Getting the Ideal Score\n",
    "'''ideal, _, _ = evaluating_model(LeaveOneOut())\n",
    "print('Ideal: %.3f' % ideal)'''\n",
    "\n",
    "folds = range(10,11)\n",
    "\n",
    "means, mins, maxs = list(), list(), list()\n",
    "\n",
    "for k in folds:\n",
    "    # define the test condition\n",
    "    cv = KFold(n_splits=k, shuffle=True, random_state=1)\n",
    "    # evaluate k value\n",
    "    k_mean, k_min, k_max = evaluating_model(cv)\n",
    "    # report performance\n",
    "    print('> folds=%d, accuracy=%.3f (%.3f,%.3f)' % (k, k_mean, k_min, k_max))\n",
    "    # store mean accuracy\n",
    "    means.append(k_mean)\n",
    "    # store min and max relative to the mean\n",
    "    mins.append(k_mean - k_min)\n",
    "    maxs.append(k_max - k_mean)\n",
    "\n",
    "# line plot of k mean values with min/max error bars\n",
    "pyplot.errorbar(folds, means, yerr=[mins, maxs], fmt='o')\n",
    "# plot the ideal case in a separate color\n",
    "# pyplot.plot(folds, [ideal for _ in range(len(folds))], color='r')\n",
    "# show the plot\n",
    "pyplot.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   | max_depth | min_sa... | min_sa... | n_esti... |\n",
      "-------------------------------------------------------------------------\n",
      "| \u001b[0m1        \u001b[0m | \u001b[0m0.9115   \u001b[0m | \u001b[0m13.02    \u001b[0m | \u001b[0m17.74    \u001b[0m | \u001b[0m44.73    \u001b[0m | \u001b[0m1.177e+03\u001b[0m |\n",
      "| \u001b[0m2        \u001b[0m | \u001b[0m0.8584   \u001b[0m | \u001b[0m7.316    \u001b[0m | \u001b[0m15.77    \u001b[0m | \u001b[0m4.203    \u001b[0m | \u001b[0m688.3    \u001b[0m |\n",
      "| \u001b[0m3        \u001b[0m | \u001b[0m0.8432   \u001b[0m | \u001b[0m6.296    \u001b[0m | \u001b[0m34.43    \u001b[0m | \u001b[0m99.09    \u001b[0m | \u001b[0m432.8    \u001b[0m |\n",
      "| \u001b[0m4        \u001b[0m | \u001b[0m0.7562   \u001b[0m | \u001b[0m3.461    \u001b[0m | \u001b[0m67.29    \u001b[0m | \u001b[0m62.88    \u001b[0m | \u001b[0m484.0    \u001b[0m |\n",
      "| \u001b[0m5        \u001b[0m | \u001b[0m0.8918   \u001b[0m | \u001b[0m10.39    \u001b[0m | \u001b[0m12.72    \u001b[0m | \u001b[0m9.248    \u001b[0m | \u001b[0m1.361e+03\u001b[0m |\n",
      "| \u001b[95m6        \u001b[0m | \u001b[95m0.9166   \u001b[0m | \u001b[95m16.29    \u001b[0m | \u001b[95m84.22    \u001b[0m | \u001b[95m81.89    \u001b[0m | \u001b[95m1.487e+03\u001b[0m |\n",
      "| \u001b[0m7        \u001b[0m | \u001b[0m0.8999   \u001b[0m | \u001b[0m12.39    \u001b[0m | \u001b[0m81.56    \u001b[0m | \u001b[0m43.29    \u001b[0m | \u001b[0m138.4    \u001b[0m |\n",
      "| \u001b[0m8        \u001b[0m | \u001b[0m0.8921   \u001b[0m | \u001b[0m10.17    \u001b[0m | \u001b[0m11.43    \u001b[0m | \u001b[0m82.09    \u001b[0m | \u001b[0m1.077e+03\u001b[0m |\n",
      "| \u001b[0m9        \u001b[0m | \u001b[0m0.9039   \u001b[0m | \u001b[0m12.18    \u001b[0m | \u001b[0m28.15    \u001b[0m | \u001b[0m99.85    \u001b[0m | \u001b[0m293.3    \u001b[0m |\n",
      "| \u001b[0m10       \u001b[0m | \u001b[0m0.9088   \u001b[0m | \u001b[0m13.08    \u001b[0m | \u001b[0m49.02    \u001b[0m | \u001b[0m41.69    \u001b[0m | \u001b[0m1.119e+03\u001b[0m |\n",
      "| \u001b[0m11       \u001b[0m | \u001b[0m0.8711   \u001b[0m | \u001b[0m7.811    \u001b[0m | \u001b[0m40.65    \u001b[0m | \u001b[0m33.26    \u001b[0m | \u001b[0m1.426e+03\u001b[0m |\n",
      "| \u001b[95m12       \u001b[0m | \u001b[95m0.9219   \u001b[0m | \u001b[95m18.54    \u001b[0m | \u001b[95m81.57    \u001b[0m | \u001b[95m5.34     \u001b[0m | \u001b[95m1.421e+03\u001b[0m |\n",
      "| \u001b[95m13       \u001b[0m | \u001b[95m0.9221   \u001b[0m | \u001b[95m19.11    \u001b[0m | \u001b[95m80.85    \u001b[0m | \u001b[95m49.17    \u001b[0m | \u001b[95m1.453e+03\u001b[0m |\n",
      "| \u001b[0m14       \u001b[0m | \u001b[0m0.8902   \u001b[0m | \u001b[0m9.506    \u001b[0m | \u001b[0m32.57    \u001b[0m | \u001b[0m3.611    \u001b[0m | \u001b[0m153.5    \u001b[0m |\n",
      "| \u001b[0m15       \u001b[0m | \u001b[0m0.7554   \u001b[0m | \u001b[0m2.956    \u001b[0m | \u001b[0m13.67    \u001b[0m | \u001b[0m5.272    \u001b[0m | \u001b[0m417.0    \u001b[0m |\n",
      "| \u001b[0m16       \u001b[0m | \u001b[0m0.9054   \u001b[0m | \u001b[0m11.79    \u001b[0m | \u001b[0m18.68    \u001b[0m | \u001b[0m19.58    \u001b[0m | \u001b[0m309.5    \u001b[0m |\n",
      "| \u001b[0m17       \u001b[0m | \u001b[0m0.9134   \u001b[0m | \u001b[0m14.29    \u001b[0m | \u001b[0m47.43    \u001b[0m | \u001b[0m77.29    \u001b[0m | \u001b[0m1.036e+03\u001b[0m |\n",
      "| \u001b[0m18       \u001b[0m | \u001b[0m0.8903   \u001b[0m | \u001b[0m9.943    \u001b[0m | \u001b[0m59.93    \u001b[0m | \u001b[0m47.24    \u001b[0m | \u001b[0m1.449e+03\u001b[0m |\n",
      "| \u001b[0m19       \u001b[0m | \u001b[0m0.8252   \u001b[0m | \u001b[0m4.661    \u001b[0m | \u001b[0m90.77    \u001b[0m | \u001b[0m50.8     \u001b[0m | \u001b[0m929.5    \u001b[0m |\n",
      "| \u001b[0m20       \u001b[0m | \u001b[0m0.9164   \u001b[0m | \u001b[0m14.32    \u001b[0m | \u001b[0m18.57    \u001b[0m | \u001b[0m86.74    \u001b[0m | \u001b[0m774.9    \u001b[0m |\n",
      "| \u001b[0m21       \u001b[0m | \u001b[0m0.9204   \u001b[0m | \u001b[0m20.0     \u001b[0m | \u001b[0m100.0    \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m1.5e+03  \u001b[0m |\n",
      "| \u001b[0m22       \u001b[0m | \u001b[0m0.9049   \u001b[0m | \u001b[0m12.32    \u001b[0m | \u001b[0m21.68    \u001b[0m | \u001b[0m87.63    \u001b[0m | \u001b[0m777.7    \u001b[0m |\n",
      "| \u001b[95m23       \u001b[0m | \u001b[95m0.9426   \u001b[0m | \u001b[95m20.0     \u001b[0m | \u001b[95m1.0      \u001b[0m | \u001b[95m100.0    \u001b[0m | \u001b[95m720.4    \u001b[0m |\n",
      "| \u001b[0m24       \u001b[0m | \u001b[0m0.9205   \u001b[0m | \u001b[0m20.0     \u001b[0m | \u001b[0m100.0    \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m1.317e+03\u001b[0m |\n",
      "=========================================================================\n",
      "It takes 2449.1163991491 minutes\n"
     ]
    }
   ],
   "source": [
    "from bayes_opt import BayesianOptimization\n",
    "\n",
    "def rf_cl_bo(max_depth, n_estimators, min_samples_leaf, min_samples_split):\n",
    "    params_rf = {}\n",
    "    params_rf['max_features'] = 'sqrt'\n",
    "    params_rf['max_depth'] = round(max_depth)\n",
    "    params_rf['n_estimators'] = round(n_estimators)\n",
    "    params_rf['min_samples_leaf'] = round(min_samples_leaf)\n",
    "    params_rf['min_samples_split'] = round(min_samples_split)\n",
    "    scores = cross_val_score(RandomForestClassifier(random_state=123, **params_rf),\n",
    "                             x_up_train, y_up_train, scoring='accuracy', cv=5).mean()\n",
    "    score = scores.mean()\n",
    "    return score\n",
    "# Run Bayesian Optimization\n",
    "start = time.time()\n",
    "params_rf ={\n",
    "    'max_depth':(2, 20),\n",
    "    'n_estimators':(100, 1500),\n",
    "    'min_samples_leaf':(1,100),\n",
    "    'min_samples_split':(2,100) \n",
    "}\n",
    "rf_bo = BayesianOptimization(rf_cl_bo, params_rf, random_state=111)\n",
    "rf_bo.maximize(init_points=20, n_iter=4)\n",
    "print('It takes %s minutes' % ((time.time() - start)/60))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
