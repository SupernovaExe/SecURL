{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RF Classifier with Wrapper-Based FS (Lexical + Content)\n",
    "\n",
    "Steven Sison | March 9, 2024"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This document will be used to train a model using the reduced feature set obtain by using the wrapper-based method, forward feature selection. The model will be evaluated in terms of the usual metrics (accuracy, precision, F1-score, recall) as well as the training time. The model will also be stored for future evaluation purposes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preliminaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Loading the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd                     # For data transformation\n",
    "import numpy as numpy                   # For scientific calculations\n",
    "import seaborn as sns                   # For data visualizations\n",
    "import matplotlib.pyplot as plt         # For plotting\n",
    "import plotly.graph_objects as go       # For plotting\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, cross_val_predict\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score, classification_report\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score, ConfusionMatrixDisplay\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "import time\n",
    "from datetime import datetime\n",
    "import joblib\n",
    "import os\n",
    "\n",
    "print(os.getcwd())\n",
    "\n",
    "dataset = pd.read_csv(\"../../../02_feature-engineering/final-datasets/binary_unbalanced_with_lexicalcontent.csv\")      # Loading the dataset\n",
    "x_train, x_test, y_train, y_test = train_test_split(dataset.drop(columns=['url_type']), dataset['url_type'], test_size = 0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Preprocessing (Balancing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['url_type'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Removing Unnecessary Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "important_features_wrapper = ['blank_spaces_count', \n",
    "                              'word_count', \n",
    "                              'js_count', \n",
    "                              'js_unescape_count', \n",
    "                              'title_tag_presence', \n",
    "                              'iframe_count', \n",
    "                              'meta_tag_count', \n",
    "                              'input_tag_count', \n",
    "                              'url_length', \n",
    "                              'url_domain_entropy', \n",
    "                              'url_query_length', \n",
    "                              'url_number_of_digits', \n",
    "                              'url_host_length', \n",
    "                              'url_number_of_subdirectories', \n",
    "                              'get_tld', \n",
    "                              'url_domain_len', \n",
    "                              'url_number_of_fragments', \n",
    "                              'url_num_periods', \n",
    "                              'url_num_forward_slash', \n",
    "                              'has_account_in_string', \n",
    "                              'has_confirm_in_string', \n",
    "                              'has_linkeq_in_string', \n",
    "                              'has_payment_in_string', \n",
    "                              'has_php_in_string']\n",
    "\n",
    "X_test = x_test[important_features_wrapper]\n",
    "X_train = x_train[important_features_wrapper]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hyper-parameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "from sklearn.metrics import mean_squared_error # or any other metric\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Define the objective function for Optuna\n",
    "def objective(trial):\n",
    "    # Define the search space for hyperparameters\n",
    "    param = {\n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 10),\n",
    "        'min_samples_split': trial.suggest_int('min_samples_split', 2, 100),\n",
    "        'max_leaf_nodes': trial.suggest_int('max_leaf_nodes', 2, 100),\n",
    "        'min_samples_leaf': trial.suggest_int('min_samples_leaf', 2, 100),\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 300, 3000),\n",
    "        'max_samples': trial.suggest_float('max_sample', 0, 1),\n",
    "        'max_features': trial.suggest_int('max_features', 1, len(important_features_wrapper))\n",
    "    }\n",
    "    \n",
    "    # Split the data into further training and validation sets (three sets are preferable)\n",
    "    train_data, valid_data, train_target, valid_target = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
    "    \n",
    "    # Train the model with early stopping\n",
    "    scores = cross_val_score(RandomForestClassifier(random_state=123, **param, warm_start = True, n_jobs = 16),\n",
    "                             X_train, y_train, scoring='neg_mean_absolute_error', cv=5).mean()\n",
    "    score = scores.mean()\n",
    "    \n",
    "    return score\n",
    "\n",
    "# Create an Optuna study and optimize the objective function\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=25) # Control the number of trials\n",
    "\n",
    "# Print the best hyperparameters and the best RMSE\n",
    "best_params = study.best_params\n",
    "best_error = study.best_value\n",
    "print(\"Best Hyperparameters (12 Features): \", best_params)\n",
    "print(\"Best Error (12 Features): \", best_error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# Initialize CV\n",
    "cv = KFold(n_splits=10, shuffle=True, random_state=1)\n",
    "\n",
    "# Initialize the model\n",
    "rf_classifier = Pipeline([\n",
    "    ('classifier', RandomForestClassifier(random_state=123, **best_params, warm_start = True, n_jobs = 16))\n",
    "])\n",
    "\n",
    "# Train the Model\n",
    "rf_classifier.fit(X_train, y_train)\n",
    "y_pred = rf_classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification Report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''# Confusion Matrix for 12 Features\n",
    "cm_up = confusion_matrix(y_test, y_pred_10, labels=rf_classifier_19.classes_)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix = cm_up, display_labels = rf_classifier_19.classes_)\n",
    "disp.plot()\n",
    "plt.show()'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''# Cross Validation Score\n",
    "scores = cross_val_score(XGBClassifier(random_state=45, **params_gbm),\n",
    "                        x_train, y_train, scoring='accuracy', cv=cv).mean()\n",
    "\n",
    "print(scores)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dumping the model\n",
    "joblib.dump(rf_classifier, 'rf_ffs_lexical-content.sav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import content_generator_wrapper\n",
    "import time\n",
    "\n",
    "def rf_predict_maliciousness(url):\n",
    "\n",
    "    numerical_values = content_generator_wrapper.feature_generator(url)\n",
    "\n",
    "    match rf_classifier.predict(numerical_values):\n",
    "        case 0:\n",
    "            return \"Benign\"\n",
    "        case 1:\n",
    "            return \"Defacement\"\n",
    "        case 2:\n",
    "            return \"Phishing\"\n",
    "        case 3:\n",
    "            return \"Malware\"\n",
    "\n",
    "url = \"www.facebook.com/\"\n",
    "print(\"Current URL: \"+url)\n",
    "\n",
    "print(\"------------- Wrapper-Based (Lexical + Content) -------------\")\n",
    "for i in range(15):\n",
    "    start = time.perf_counter()\n",
    "    prediction = rf_predict_maliciousness(url)\n",
    "    end = time.perf_counter()\n",
    "    print(\"Trial \"+str(i))\n",
    "    print(prediction)\n",
    "    print(end-start)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
